ðŸ”§ End-to-End Pipeline
1. Data Collection â†’ Preprocessing

Collect raw chat logs / FAQs â†’ save as .csv

utils/preprocessing.py:

clean text (lowercase, remove noise)
tokenize
map synonyms (using nlu/data/synonyms.csv)
Output â†’ processed_intents.csv

2. NLU Training Pipeline
Intent Classification

nlu/intent_classifier.py

train ML/DL model (e.g., Logistic Regression / BERT)
save model â†’ models/intent_model.pkl

Entity Extraction

nlu/entity_extractor.py

rule-based / spaCy NER
save entity patterns â†’ models/entities.json

3. Inference Pipeline

Load models â†’ classify intent + extract entities

Pass structured result to response layer:

{
  "intent": "refund_status",
  "entities": {"order_id": "1234"}
}

4. Response Generation

responses/response_generator.py

map intent â†’ template or LLM response
responses/fallback.py

low confidence? â†’ fallback message
Uses config.py thresholds for confidence.

5. Streamlit App Pipeline

app/main.py

User input â†’ preprocessing â†’ NLU â†’ response generator
Display final answer
Log interactions via utils/logger.py

6. Testing Pipeline

tests/

intent tests â†’ test_intents.py
response mapping â†’ test_responses.py
end-to-end UI check â†’ test_app.py

7. Monitoring Pipeline

Log predictions + confidence

Track:
accuracy drift
fallback rate
new unseen queries â†’ push back to data collection
